import torch
import torch.nn as nn
import cv2
import numpy as np
import os
from PIL import Image
import matplotlib.pyplot as plt
import json
from datetime import datetime
import glob

# é…ç½®é¡åˆ¥ï¼ˆèˆ‡è¨“ç·´æ™‚ä¿æŒä¸€è‡´ï¼‰
class Config:
    # æ¨¡å‹åƒæ•¸
    IMAGE_SIZE = (640, 640)
    NUM_CLASSES = 2  # èƒŒæ™¯ + è¡€ç®¡
    
    # æ¨¡å‹è·¯å¾‘
    MODEL_PATH = "models/best_vessel_cnn.pth"  # æˆ– best_vessel_cnn_simple.pth
    
    # æ¨ç†åƒæ•¸
    CONFIDENCE_THRESHOLD = 0.5  # ç½®ä¿¡åº¦é–¾å€¼
    
    @classmethod
    def to_dict(cls):
        """å°‡é…ç½®è½‰æ›ç‚ºå¯åºåˆ—åŒ–çš„å­—å…¸"""
        return {
            'IMAGE_SIZE': cls.IMAGE_SIZE,
            'NUM_CLASSES': cls.NUM_CLASSES,
            'MODEL_PATH': cls.MODEL_PATH,
            'CONFIDENCE_THRESHOLD': cls.CONFIDENCE_THRESHOLD
        }

# CNNæ¨¡å‹å®šç¾©ï¼ˆèˆ‡è¨“ç·´æ™‚å®Œå…¨ç›¸åŒï¼‰
class VesselCNN(nn.Module):
    def __init__(self, num_classes=2):
        super(VesselCNN, self).__init__()
        
        # ä½¿ç”¨æ›´å°‘çš„é€šé“æ•¸ä¾†ç¯€çœè¨˜æ†¶é«”
        self.features = nn.Sequential(
            # ç¬¬ä¸€å±¤ï¼šRGB -> 16ç‰¹å¾µ
            nn.Conv2d(3, 16, kernel_size=1, padding=0),
            nn.BatchNorm2d(16),
            nn.ReLU(inplace=True),
            
            # ç¬¬äºŒå±¤ï¼š16 -> 32ç‰¹å¾µ
            nn.Conv2d(16, 32, kernel_size=1, padding=0),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            
            # ç¬¬ä¸‰å±¤ï¼š32 -> 64ç‰¹å¾µ
            nn.Conv2d(32, 64, kernel_size=1, padding=0),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            
            # ç¬¬å››å±¤ï¼š64 -> 32ç‰¹å¾µ
            nn.Conv2d(64, 32, kernel_size=1, padding=0),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            
            # ç¬¬äº”å±¤ï¼š32 -> 16ç‰¹å¾µ
            nn.Conv2d(32, 16, kernel_size=1, padding=0),
            nn.BatchNorm2d(16),
            nn.ReLU(inplace=True),
            
            # è¼¸å‡ºå±¤ï¼š16 -> 2é¡åˆ¥ (èƒŒæ™¯/è¡€ç®¡)
            nn.Conv2d(16, num_classes, kernel_size=1, padding=0)
        )
        
    def forward(self, x):
        return self.features(x)

# è¡€ç®¡åˆ†å‰²æ¨ç†é¡åˆ¥
class VesselSegmentationInference:
    def __init__(self, model_path=None, device=None):
        """
        åˆå§‹åŒ–æ¨ç†æ¨¡å‹
        
        Args:
            model_path: æ¨¡å‹æª”æ¡ˆè·¯å¾‘
            device: è¨ˆç®—è¨­å‚™ ('cuda' æˆ– 'cpu')
        """
        self.model_path = model_path or Config.MODEL_PATH
        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        self.model_info = {}
        
        print(f"ğŸ”§ åˆå§‹åŒ–æ¨ç†æ¨¡å‹...")
        print(f"ğŸ“± ä½¿ç”¨è¨­å‚™: {self.device}")
        
        if torch.cuda.is_available() and self.device == 'cuda':
            print(f"ğŸ® GPU: {torch.cuda.get_device_name()}")
        
        self.load_model()
    
    def load_model(self):
        """è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹"""
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ: {self.model_path}")
        
        print(f"ğŸ“‚ è¼‰å…¥æ¨¡å‹: {self.model_path}")
        
        try:
            # è¼‰å…¥æ¨¡å‹æª¢æŸ¥é»
            checkpoint = torch.load(self.model_path, map_location=self.device)
            
            # åˆå§‹åŒ–æ¨¡å‹
            self.model = VesselCNN(num_classes=Config.NUM_CLASSES)
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.to(self.device)
            self.model.eval()
            
            # å„²å­˜æ¨¡å‹è³‡è¨Š
            self.model_info = {
                'epoch': checkpoint.get('epoch', 'Unknown'),
                'best_val_iou': checkpoint.get('best_val_iou', 'Unknown'),
                'config': checkpoint.get('config', {}),
                'loaded_at': datetime.now().isoformat()
            }
            
            print(f"âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ!")
            print(f"ğŸ“Š è¨“ç·´è¼ªæ•¸: {self.model_info['epoch']}")
            print(f"ğŸ¯ æœ€ä½³ IoU: {self.model_info['best_val_iou']:.4f}" if isinstance(self.model_info['best_val_iou'], float) else f"ğŸ¯ æœ€ä½³ IoU: {self.model_info['best_val_iou']}")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            raise
    
    def preprocess_image(self, image_path_or_array):
        """
        é è™•ç†è¼¸å…¥å½±åƒ
        
        Args:
            image_path_or_array: å½±åƒè·¯å¾‘æˆ–numpyé™£åˆ—
            
        Returns:
            tensor: é è™•ç†å¾Œçš„å¼µé‡
            original_size: åŸå§‹å½±åƒå°ºå¯¸
        """
        # è®€å–å½±åƒ
        if isinstance(image_path_or_array, str):
            # å¾è·¯å¾‘è®€å–
            if not os.path.exists(image_path_or_array):
                raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°å½±åƒæª”æ¡ˆ: {image_path_or_array}")
            
            try:
                # å˜—è©¦ç”¨OpenCVè®€å–
                image = cv2.imread(image_path_or_array)
                if image is not None:
                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                else:
                    # ä½¿ç”¨PILè®€å–
                    image = Image.open(image_path_or_array).convert('RGB')
                    image = np.array(image)
            except Exception as e:
                raise ValueError(f"âŒ ç„¡æ³•è®€å–å½±åƒ: {e}")
        else:
            # ç›´æ¥ä½¿ç”¨numpyé™£åˆ—
            image = image_path_or_array.copy()
        
        # è¨˜éŒ„åŸå§‹å°ºå¯¸
        original_size = (image.shape[1], image.shape[0])  # (width, height)
        
        # èª¿æ•´å°ºå¯¸åˆ°æ¨¡å‹è¼¸å…¥å¤§å°
        image_resized = cv2.resize(image, Config.IMAGE_SIZE)
        
        # æ­£è¦åŒ–åˆ° [0, 1]
        image_normalized = image_resized.astype(np.float32) / 255.0
        
        # è½‰æ›ç‚ºå¼µé‡ (H, W, C) -> (1, C, H, W)
        image_tensor = torch.FloatTensor(image_normalized).permute(2, 0, 1).unsqueeze(0)
        
        return image_tensor.to(self.device), original_size
    
    def postprocess_prediction(self, prediction, original_size, apply_threshold=True):
        """
        å¾Œè™•ç†é æ¸¬çµæœ
        
        Args:
            prediction: æ¨¡å‹é æ¸¬è¼¸å‡º
            original_size: åŸå§‹å½±åƒå°ºå¯¸ (width, height)
            apply_threshold: æ˜¯å¦æ‡‰ç”¨ç½®ä¿¡åº¦é–¾å€¼
            
        Returns:
            dict: åŒ…å«å„ç¨®æ ¼å¼çš„é æ¸¬çµæœ
        """
        # ç²å–é æ¸¬æ©Ÿç‡å’Œé¡åˆ¥
        with torch.no_grad():
            # æ‡‰ç”¨softmaxç²å¾—æ©Ÿç‡
            probabilities = torch.softmax(prediction, dim=1)
            vessel_prob = probabilities[0, 1].cpu().numpy()  # è¡€ç®¡æ©Ÿç‡
            
            # ç²å–é æ¸¬é¡åˆ¥
            _, predicted_class = torch.max(prediction, 1)
            predicted_mask = predicted_class[0].cpu().numpy()
        
        # èª¿æ•´å›åŸå§‹å°ºå¯¸
        vessel_prob_resized = cv2.resize(vessel_prob, original_size)
        predicted_mask_resized = cv2.resize(predicted_mask.astype(np.uint8), original_size, 
                                          interpolation=cv2.INTER_NEAREST)
        
        # æ‡‰ç”¨ç½®ä¿¡åº¦é–¾å€¼ï¼ˆå¯é¸ï¼‰
        if apply_threshold:
            thresholded_mask = (vessel_prob_resized > Config.CONFIDENCE_THRESHOLD).astype(np.uint8)
        else:
            thresholded_mask = predicted_mask_resized
        
        return {
            'vessel_probability': vessel_prob_resized,  # è¡€ç®¡æ©Ÿç‡åœ– [0-1]
            'predicted_mask': predicted_mask_resized,   # é æ¸¬é®ç½© [0,1]
            'thresholded_mask': thresholded_mask,       # é–¾å€¼åŒ–é®ç½© [0,1]
            'vessel_probability_uint8': (vessel_prob_resized * 255).astype(np.uint8),  # 8ä½æ©Ÿç‡åœ–
            'binary_mask_uint8': (thresholded_mask * 255).astype(np.uint8)  # 8ä½äºŒå€¼é®ç½©
        }
    
    def predict_single_image(self, image_path_or_array, save_results=False, output_dir="results"):
        """
        å°å–®å¼µå½±åƒé€²è¡Œè¡€ç®¡åˆ†å‰²é æ¸¬
        
        Args:
            image_path_or_array: å½±åƒè·¯å¾‘æˆ–numpyé™£åˆ—
            save_results: æ˜¯å¦å„²å­˜çµæœ
            output_dir: çµæœå„²å­˜ç›®éŒ„
            
        Returns:
            dict: é æ¸¬çµæœ
        """
        if self.model is None:
            raise RuntimeError("âŒ æ¨¡å‹å°šæœªè¼‰å…¥!")
        
        print(f"ğŸ” è™•ç†å½±åƒ...")
        
        # é è™•ç†
        image_tensor, original_size = self.preprocess_image(image_path_or_array)
        
        # æ¨ç†
        with torch.no_grad():
            prediction = self.model(image_tensor)
        
        # å¾Œè™•ç†
        results = self.postprocess_prediction(prediction, original_size)
        
        # è¨ˆç®—çµ±è¨ˆè³‡è¨Š
        vessel_pixels = np.sum(results['thresholded_mask'])
        total_pixels = results['thresholded_mask'].size
        vessel_ratio = vessel_pixels / total_pixels
        
        results['statistics'] = {
            'vessel_pixels': int(vessel_pixels),
            'total_pixels': int(total_pixels),
            'vessel_ratio': float(vessel_ratio),
            'image_size': original_size
        }
        
        print(f"âœ… é æ¸¬å®Œæˆ!")
        print(f"ğŸ“Š è¡€ç®¡åƒç´ : {vessel_pixels:,} / {total_pixels:,} ({vessel_ratio:.2%})")
        
        # å„²å­˜çµæœï¼ˆå¯é¸ï¼‰
        if save_results:
            self.save_prediction_results(image_path_or_array, results, output_dir)
        
        return results
    
    def predict_batch_images(self, image_paths, save_results=False, output_dir="results"):
        """
        æ‰¹æ¬¡è™•ç†å¤šå¼µå½±åƒ
        
        Args:
            image_paths: å½±åƒè·¯å¾‘åˆ—è¡¨
            save_results: æ˜¯å¦å„²å­˜çµæœ
            output_dir: çµæœå„²å­˜ç›®éŒ„
            
        Returns:
            list: æ‰€æœ‰é æ¸¬çµæœ
        """
        print(f"ğŸ”„ æ‰¹æ¬¡è™•ç† {len(image_paths)} å¼µå½±åƒ...")
        
        all_results = []
        for i, image_path in enumerate(image_paths):
            print(f"\\nè™•ç† {i+1}/{len(image_paths)}: {os.path.basename(image_path)}")
            
            try:
                result = self.predict_single_image(image_path, save_results, output_dir)
                result['image_path'] = image_path
                all_results.append(result)
            except Exception as e:
                print(f"âŒ è™•ç†å¤±æ•—: {e}")
                continue
        
        print(f"\\nğŸ‰ æ‰¹æ¬¡è™•ç†å®Œæˆ! æˆåŠŸè™•ç† {len(all_results)}/{len(image_paths)} å¼µå½±åƒ")
        return all_results
    
    def save_prediction_results(self, image_path_or_array, results, output_dir="results"):
        """å„²å­˜é æ¸¬çµæœ"""
        os.makedirs(output_dir, exist_ok=True)
        
        # ç²å–æª”æ¡ˆåç¨±
        if isinstance(image_path_or_array, str):
            base_name = os.path.splitext(os.path.basename(image_path_or_array))[0]
        else:
            base_name = f"prediction_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # å„²å­˜å„ç¨®æ ¼å¼çš„çµæœ
        cv2.imwrite(os.path.join(output_dir, f"{base_name}_vessel_prob.png"), 
                   results['vessel_probability_uint8'])
        cv2.imwrite(os.path.join(output_dir, f"{base_name}_binary_mask.png"), 
                   results['binary_mask_uint8'])
        
        # å„²å­˜çµ±è¨ˆè³‡è¨Š
        stats_file = os.path.join(output_dir, f"{base_name}_stats.json")
        with open(stats_file, 'w') as f:
            json.dump({
                'statistics': results['statistics'],
                'model_info': self.model_info,
                'prediction_time': datetime.now().isoformat()
            }, f, indent=2)
        
        print(f"ğŸ’¾ çµæœå·²å„²å­˜åˆ°: {output_dir}")
    
    def visualize_prediction(self, image_path_or_array, results=None, figsize=(15, 5)):
        """
        è¦–è¦ºåŒ–é æ¸¬çµæœ
        
        Args:
            image_path_or_array: åŸå§‹å½±åƒ
            results: é æ¸¬çµæœï¼ˆå¦‚æœç‚ºNoneå‰‡é‡æ–°é æ¸¬ï¼‰
            figsize: åœ–ç‰‡å¤§å°
        """
        # å¦‚æœæ²’æœ‰æä¾›çµæœï¼Œå‰‡é€²è¡Œé æ¸¬
        if results is None:
            results = self.predict_single_image(image_path_or_array)
        
        # è®€å–åŸå§‹å½±åƒ
        if isinstance(image_path_or_array, str):
            original_image = cv2.imread(image_path_or_array)
            original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)
            title_suffix = os.path.basename(image_path_or_array)
        else:
            original_image = image_path_or_array
            title_suffix = "Array Input"
        
        # å‰µå»ºè¦–è¦ºåŒ–
        fig, axes = plt.subplots(1, 3, figsize=figsize)
        
        # åŸå§‹å½±åƒ
        axes[0].imshow(original_image)
        axes[0].set_title(f'åŸå§‹å½±åƒ\\n{title_suffix}')
        axes[0].axis('off')
        
        # è¡€ç®¡æ©Ÿç‡åœ–
        im1 = axes[1].imshow(results['vessel_probability'], cmap='hot', vmin=0, vmax=1)
        axes[1].set_title(f'è¡€ç®¡æ©Ÿç‡åœ–\\næœ€å¤§å€¼: {results["vessel_probability"].max():.3f}')
        axes[1].axis('off')
        plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)
        
        # äºŒå€¼åŒ–é®ç½©
        axes[2].imshow(results['thresholded_mask'], cmap='gray', vmin=0, vmax=1)
        axes[2].set_title(f'è¡€ç®¡åˆ†å‰²çµæœ\\nè¡€ç®¡æ¯”ä¾‹: {results["statistics"]["vessel_ratio"]:.2%}')
        axes[2].axis('off')
        
        plt.tight_layout()
        plt.show()

# ä¾¿æ·å‡½æ•¸
def quick_predict(image_path, model_path=None, visualize=True, save_results=False):
    """
    å¿«é€Ÿé æ¸¬å–®å¼µå½±åƒ
    
    Args:
        image_path: å½±åƒè·¯å¾‘
        model_path: æ¨¡å‹è·¯å¾‘ï¼ˆå¯é¸ï¼‰
        visualize: æ˜¯å¦é¡¯ç¤ºçµæœ
        save_results: æ˜¯å¦å„²å­˜çµæœ
        
    Returns:
        é æ¸¬çµæœ
    """
    # åˆå§‹åŒ–æ¨ç†æ¨¡å‹
    inferencer = VesselSegmentationInference(model_path)
    
    # é€²è¡Œé æ¸¬
    results = inferencer.predict_single_image(image_path, save_results=save_results)
    
    # è¦–è¦ºåŒ–ï¼ˆå¯é¸ï¼‰
    if visualize:
        inferencer.visualize_prediction(image_path, results)
    
    return results

def batch_predict(image_dir, model_path=None, save_results=True, output_dir="batch_results"):
    """
    æ‰¹æ¬¡é æ¸¬è³‡æ–™å¤¾ä¸­çš„æ‰€æœ‰å½±åƒ
    
    Args:
        image_dir: å½±åƒè³‡æ–™å¤¾è·¯å¾‘
        model_path: æ¨¡å‹è·¯å¾‘ï¼ˆå¯é¸ï¼‰
        save_results: æ˜¯å¦å„²å­˜çµæœ
        output_dir: çµæœå„²å­˜ç›®éŒ„
        
    Returns:
        æ‰€æœ‰é æ¸¬çµæœ
    """
    # æ‰¾åˆ°æ‰€æœ‰å½±åƒæª”æ¡ˆ
    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.tif', '*.tiff', 
                       '*.JPG', '*.JPEG', '*.PNG', '*.TIF', '*.TIFF']
    image_paths = []
    for ext in image_extensions:
        image_paths.extend(glob.glob(os.path.join(image_dir, ext)))
    
    if not image_paths:
        print(f"âŒ åœ¨ {image_dir} ä¸­æ‰¾ä¸åˆ°ä»»ä½•å½±åƒæª”æ¡ˆ!")
        return []
    
    print(f"ğŸ“ æ‰¾åˆ° {len(image_paths)} å¼µå½±åƒ")
    
    # åˆå§‹åŒ–æ¨ç†æ¨¡å‹
    inferencer = VesselSegmentationInference(model_path)
    
    # æ‰¹æ¬¡é æ¸¬
    results = inferencer.predict_batch_images(image_paths, save_results, output_dir)
    
    return results

# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    print("ğŸ©¸ è¡€ç®¡åˆ†å‰²æ¨ç†æ¨¡å‹")
    print("=" * 50)
    
    # ç¯„ä¾‹1: å¿«é€Ÿé æ¸¬å–®å¼µå½±åƒ
    print("\\nğŸ“ ä½¿ç”¨ç¯„ä¾‹:")
    print("1. å¿«é€Ÿé æ¸¬å–®å¼µå½±åƒ:")
    print("   results = quick_predict('path/to/your/image.jpg')")
    
    print("\\n2. æ‰¹æ¬¡é æ¸¬è³‡æ–™å¤¾:")
    print("   results = batch_predict('path/to/image/folder')")
    
    print("\\n3. è‡ªå®šç¾©æ¨ç†:")
    print("   inferencer = VesselSegmentationInference('models/best_vessel_cnn.pth')")
    print("   results = inferencer.predict_single_image('image.jpg', save_results=True)")
    print("   inferencer.visualize_prediction('image.jpg', results)")
    
    print("\\n4. æª¢æŸ¥å¯ç”¨çš„æ¨¡å‹æª”æ¡ˆ:")
    model_files = glob.glob("models/*.pth")
    if model_files:
        print("   å¯ç”¨æ¨¡å‹:")
        for model_file in model_files:
            print(f"   - {model_file}")
    else:
        print("   âŒ åœ¨ models/ ç›®éŒ„ä¸­æ‰¾ä¸åˆ° .pth æª”æ¡ˆ")
        print("   è«‹ç¢ºä¿è¨“ç·´å®Œæˆä¸¦ä¸”æ¨¡å‹å·²å„²å­˜!")