import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import cv2
import numpy as np
import os
import glob
import random
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import json
from datetime import datetime
import gc

# é…ç½®é¡åˆ¥
class Config:
    # è³‡æ–™è·¯å¾‘
    DATA_ROOT = "D:/ROP_vein"
    DATASETS = ["CHASE_DB1", "DRIVE", "FIVES", "HRF"]
    
    # è¨“ç·´åƒæ•¸ - é‡å°RTX 4060 Laptop 8GBå„ªåŒ–
    IMAGE_SIZE = (640, 640)
    BATCH_SIZE = 4  # å¾32é™ä½åˆ°4ï¼Œé¿å…è¨˜æ†¶é«”ä¸è¶³
    LEARNING_RATE = 1e-4
    EPOCHS = 500
    
    # è³‡æ–™åˆ†å‰²æ¯”ä¾‹
    TRAIN_RATIO = 0.8
    VAL_RATIO = 0.1
    TEST_RATIO = 0.1
    
    # æ¨¡å‹åƒæ•¸
    NUM_CLASSES = 2  # èƒŒæ™¯ + è¡€ç®¡
    
    # CHASE_DB1 é®ç½©é¸é …
    USE_BOTH_CHASE_MASKS = True  # True: ä½¿ç”¨å…©ç¨®é®ç½©, False: åƒ…ä½¿ç”¨1stHO
    
    # å„²å­˜è·¯å¾‘
    MODEL_SAVE_PATH = "models/"
    LOG_PATH = "logs/"
    
    @classmethod
    def to_dict(cls):
        """å°‡é…ç½®è½‰æ›ç‚ºå¯åºåˆ—åŒ–çš„å­—å…¸"""
        return {
            'DATA_ROOT': cls.DATA_ROOT,
            'DATASETS': cls.DATASETS,
            'IMAGE_SIZE': cls.IMAGE_SIZE,
            'BATCH_SIZE': cls.BATCH_SIZE,
            'LEARNING_RATE': cls.LEARNING_RATE,
            'EPOCHS': cls.EPOCHS,
            'TRAIN_RATIO': cls.TRAIN_RATIO,
            'VAL_RATIO': cls.VAL_RATIO,
            'TEST_RATIO': cls.TEST_RATIO,
            'NUM_CLASSES': cls.NUM_CLASSES,
            'USE_BOTH_CHASE_MASKS': cls.USE_BOTH_CHASE_MASKS,
            'MODEL_SAVE_PATH': cls.MODEL_SAVE_PATH,
            'LOG_PATH': cls.LOG_PATH
        }

# è‡ªå®šç¾©è³‡æ–™é›†é¡åˆ¥
class VesselDataset(Dataset):
    def __init__(self, image_paths, mask_paths, transform=None, target_size=(640, 640)):
        self.image_paths = image_paths
        self.mask_paths = mask_paths
        self.transform = transform
        self.target_size = target_size
        
    def __len__(self):
        return len(self.image_paths)
    
    def load_image_robust(self, image_path):
        """å¼·åŒ–çš„å½±åƒè®€å–å‡½æ•¸"""
        try:
            # é¦–å…ˆå˜—è©¦ç”¨OpenCVè®€å–
            image = cv2.imread(image_path)
            if image is not None:
                return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        except:
            pass
        
        try:
            # å¦‚æœOpenCVå¤±æ•—ï¼Œä½¿ç”¨PIL
            image = Image.open(image_path).convert('RGB')
            return np.array(image)
        except:
            pass
        
        raise ValueError(f"ç„¡æ³•è®€å–å½±åƒ: {image_path}")
    
    def load_mask_robust(self, mask_path):
        """å¼·åŒ–çš„é®ç½©è®€å–å‡½æ•¸ï¼Œç‰¹åˆ¥è™•ç†GIFæ ¼å¼"""
        try:
            # æª¢æŸ¥æª”æ¡ˆå‰¯æª”å
            ext = os.path.splitext(mask_path)[1].lower()
            
            if ext == '.gif':
                # ä½¿ç”¨PILè®€å–GIFæª”æ¡ˆ
                with Image.open(mask_path) as img:
                    # è½‰æ›ç‚ºç°éš
                    mask = img.convert('L')
                    return np.array(mask)
            else:
                # ä½¿ç”¨OpenCVè®€å–å…¶ä»–æ ¼å¼
                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
                if mask is not None:
                    return mask
        except Exception as e:
            print(f"è®€å–é®ç½©å¤±æ•— (OpenCV): {mask_path}, éŒ¯èª¤: {e}")
        
        try:
            # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨PIL
            with Image.open(mask_path) as img:
                mask = img.convert('L')
                return np.array(mask)
        except Exception as e:
            print(f"è®€å–é®ç½©å¤±æ•— (PIL): {mask_path}, éŒ¯èª¤: {e}")
        
        raise ValueError(f"ç„¡æ³•è®€å–é®ç½©: {mask_path}")
    
    def __getitem__(self, idx):
        try:
            # è®€å–åŸå§‹å½±åƒ
            image = self.load_image_robust(self.image_paths[idx])
            image = cv2.resize(image, self.target_size)
            
            # è®€å–é®ç½©
            mask = self.load_mask_robust(self.mask_paths[idx])
            mask = cv2.resize(mask, self.target_size)
            
            # äºŒå€¼åŒ–é®ç½© (ç™½è‰²=è¡€ç®¡=1, é»‘è‰²=èƒŒæ™¯=0)
            mask = (mask > 127).astype(np.uint8)
            
            # æ­£è¦åŒ–å½±åƒåˆ° [0, 1]
            image = image.astype(np.float32) / 255.0
            
            # è½‰æ›ç‚º PyTorch å¼µé‡
            image = torch.FloatTensor(image).permute(2, 0, 1)  # (H, W, C) -> (C, H, W)
            mask = torch.LongTensor(mask)
            
            return image, mask
            
        except Exception as e:
            print(f"è®€å–è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            print(f"å½±åƒè·¯å¾‘: {self.image_paths[idx]}")
            print(f"é®ç½©è·¯å¾‘: {self.mask_paths[idx]}")
            # è¿”å›é›¶å¼µé‡é¿å…ç¨‹å¼å´©æ½°
            image = torch.zeros(3, self.target_size[1], self.target_size[0])
            mask = torch.zeros(self.target_size[1], self.target_size[0], dtype=torch.long)
            return image, mask

# è¨˜æ†¶é«”å„ªåŒ–çš„CNNæ¨¡å‹
class VesselCNN(nn.Module):
    def __init__(self, num_classes=2):
        super(VesselCNN, self).__init__()
        
        # ä½¿ç”¨æ›´å°‘çš„é€šé“æ•¸ä¾†ç¯€çœè¨˜æ†¶é«”
        self.features = nn.Sequential(
            # ç¬¬ä¸€å±¤ï¼šRGB -> 16ç‰¹å¾µ (æ¸›å°‘é€šé“æ•¸)
            nn.Conv2d(3, 16, kernel_size=1, padding=0),
            nn.BatchNorm2d(16),
            nn.ReLU(inplace=True),
            
            # ç¬¬äºŒå±¤ï¼š16 -> 32ç‰¹å¾µ
            nn.Conv2d(16, 32, kernel_size=1, padding=0),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            
            # ç¬¬ä¸‰å±¤ï¼š32 -> 64ç‰¹å¾µ
            nn.Conv2d(32, 64, kernel_size=1, padding=0),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            
            # ç¬¬å››å±¤ï¼š64 -> 32ç‰¹å¾µ
            nn.Conv2d(64, 32, kernel_size=1, padding=0),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            
            # ç¬¬äº”å±¤ï¼š32 -> 16ç‰¹å¾µ
            nn.Conv2d(32, 16, kernel_size=1, padding=0),
            nn.BatchNorm2d(16),
            nn.ReLU(inplace=True),
            
            # è¼¸å‡ºå±¤ï¼š16 -> 2é¡åˆ¥ (èƒŒæ™¯/è¡€ç®¡)
            nn.Conv2d(16, num_classes, kernel_size=1, padding=0)
        )
        
    def forward(self, x):
        return self.features(x)

# æ™ºèƒ½æª”æ¡ˆé…å°å‡½æ•¸
def find_matching_mask(image_path, dataset_name, mask_dir):
    """
    æ ¹æ“šä¸åŒè³‡æ–™é›†çš„è¦å‰‡å°‹æ‰¾å°æ‡‰çš„é®ç½©æª”æ¡ˆ
    """
    image_name = os.path.basename(image_path)
    image_stem = os.path.splitext(image_name)[0]
    
    matching_masks = []
    
    if dataset_name == "CHASE_DB1":
        # CHASE_DB1: Image_01L.jpg -> Image_01L_1stHO.png, Image_01L_2ndHO.png
        mask_candidates = [
            f"{image_stem}_1stHO.png",
            f"{image_stem}_2ndHO.png"
        ]
        
        for mask_name in mask_candidates:
            mask_path = os.path.join(mask_dir, mask_name)
            if os.path.exists(mask_path):
                matching_masks.append(mask_path)
                
    elif dataset_name == "DRIVE":
        # DRIVE: 21_training.tif -> 21_manual1.gif
        if "_training" in image_stem:
            number = image_stem.replace("_training", "")
            mask_name = f"{number}_manual1.gif"
            mask_path = os.path.join(mask_dir, mask_name)
            if os.path.exists(mask_path):
                matching_masks.append(mask_path)
                
    elif dataset_name == "HRF":
        # HRF: 01_dr.JPG -> 01_dr.tif
        mask_name = f"{image_stem}.tif"
        mask_path = os.path.join(mask_dir, mask_name)
        if os.path.exists(mask_path):
            matching_masks.append(mask_path)
            
    elif dataset_name == "FIVES":
        # FIVES: å‡è¨­ä½¿ç”¨ç›¸åŒæª”åä½†ä¸åŒå‰¯æª”å
        mask_extensions = ['.png', '.tif', '.jpg', '.jpeg']
        for ext in mask_extensions:
            mask_name = f"{image_stem}{ext}"
            mask_path = os.path.join(mask_dir, mask_name)
            if os.path.exists(mask_path):
                matching_masks.append(mask_path)
                break
    
    return matching_masks

# æª”æ¡ˆæ ¼å¼æª¢æŸ¥å‡½æ•¸
def check_file_formats(image_paths, mask_paths):
    """æª¢æŸ¥ä¸¦å ±å‘Šæª”æ¡ˆæ ¼å¼åˆ†å¸ƒ"""
    print("\\nğŸ“Š æª”æ¡ˆæ ¼å¼åˆ†æ:")
    
    # çµ±è¨ˆå½±åƒæ ¼å¼
    image_formats = {}
    for path in image_paths:
        ext = os.path.splitext(path)[1].lower()
        image_formats[ext] = image_formats.get(ext, 0) + 1
    
    print("å½±åƒæ ¼å¼:")
    for ext, count in sorted(image_formats.items()):
        print(f"  {ext}: {count} å€‹æª”æ¡ˆ")
    
    # çµ±è¨ˆé®ç½©æ ¼å¼
    mask_formats = {}
    for path in mask_paths:
        ext = os.path.splitext(path)[1].lower()
        mask_formats[ext] = mask_formats.get(ext, 0) + 1
    
    print("é®ç½©æ ¼å¼:")
    for ext, count in sorted(mask_formats.items()):
        print(f"  {ext}: {count} å€‹æª”æ¡ˆ")
    
    # ç‰¹åˆ¥æª¢æŸ¥GIFæª”æ¡ˆ
    gif_files = [path for path in mask_paths if path.lower().endswith('.gif')]
    if gif_files:
        print(f"\\nâš ï¸ ç™¼ç¾ {len(gif_files)} å€‹GIFé®ç½©æª”æ¡ˆï¼Œå°‡ä½¿ç”¨PILè®€å–")

# è³‡æ–™è¼‰å…¥å‡½æ•¸
def load_dataset_paths(data_root, datasets):
    all_image_paths = []
    all_mask_paths = []
    
    print("æ­£åœ¨è¼‰å…¥è³‡æ–™é›†...")
    
    for dataset in datasets:
        print(f"\\nè™•ç†è³‡æ–™é›†: {dataset}")
        dataset_path = os.path.join(data_root, dataset)
        image_dir = os.path.join(dataset_path, "Images")
        mask_dir = os.path.join(dataset_path, "Masks")
        
        if not os.path.exists(image_dir):
            print(f"  âŒ Images è³‡æ–™å¤¾ä¸å­˜åœ¨: {image_dir}")
            continue
            
        if not os.path.exists(mask_dir):
            print(f"  âŒ Masks è³‡æ–™å¤¾ä¸å­˜åœ¨: {mask_dir}")
            continue
        
        # ç²å–æ‰€æœ‰å½±åƒæª”æ¡ˆ
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.tif', '*.tiff', '*.JPG', '*.JPEG', '*.PNG', '*.TIF', '*.TIFF']
        image_paths = []
        for ext in image_extensions:
            image_paths.extend(glob.glob(os.path.join(image_dir, ext)))
        
        print(f"  ğŸ“¸ æ‰¾åˆ° {len(image_paths)} å€‹å½±åƒæª”æ¡ˆ")
        
        dataset_pairs = 0
        for img_path in image_paths:
            matching_masks = find_matching_mask(img_path, dataset, mask_dir)
            
            if matching_masks:
                if dataset == "CHASE_DB1" and Config.USE_BOTH_CHASE_MASKS:
                    # ä½¿ç”¨æ‰€æœ‰æ‰¾åˆ°çš„é®ç½©
                    for mask_path in matching_masks:
                        all_image_paths.append(img_path)
                        all_mask_paths.append(mask_path)
                        dataset_pairs += 1
                else:
                    # åªä½¿ç”¨ç¬¬ä¸€å€‹æ‰¾åˆ°çš„é®ç½©ï¼ˆå°CHASE_DB1ä¾†èªªæ˜¯1stHOï¼‰
                    all_image_paths.append(img_path)
                    all_mask_paths.append(matching_masks[0])
                    dataset_pairs += 1
            else:
                print(f"  âš ï¸ æ‰¾ä¸åˆ° {os.path.basename(img_path)} å°æ‡‰çš„é®ç½©æª”æ¡ˆ")
        
        print(f"  âœ… æˆåŠŸé…å°: {dataset_pairs} çµ„")
    
    print(f"\\nç¸½å…±æ‰¾åˆ° {len(all_image_paths)} çµ„å½±åƒ-é®ç½©é…å°")
    
    # æª¢æŸ¥æª”æ¡ˆæ ¼å¼
    check_file_formats(all_image_paths, all_mask_paths)
    
    return all_image_paths, all_mask_paths

# è³‡æ–™åˆ†å‰²å‡½æ•¸
def split_dataset(image_paths, mask_paths, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):
    # ç¢ºä¿æ¯”ä¾‹ç¸½å’Œç‚º1
    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6
    
    # å‰µå»ºé…å°çš„ç´¢å¼•ä¸¦æ‰“äº‚
    indices = list(range(len(image_paths)))
    random.shuffle(indices)
    
    n = len(indices)
    train_end = int(n * train_ratio)
    val_end = int(n * (train_ratio + val_ratio))
    
    train_indices = indices[:train_end]
    val_indices = indices[train_end:val_end]
    test_indices = indices[val_end:]
    
    train_images = [image_paths[i] for i in train_indices]
    train_masks = [mask_paths[i] for i in train_indices]
    
    val_images = [image_paths[i] for i in val_indices]
    val_masks = [mask_paths[i] for i in val_indices]
    
    test_images = [image_paths[i] for i in test_indices]
    test_masks = [mask_paths[i] for i in test_indices]
    
    return (train_images, train_masks), (val_images, val_masks), (test_images, test_masks)

# è©•ä¼°æŒ‡æ¨™è¨ˆç®—
def calculate_metrics(pred, target):
    pred = pred.cpu().numpy().flatten()
    target = target.cpu().numpy().flatten()
    
    # æ··æ·†çŸ©é™£
    cm = confusion_matrix(target, pred, labels=[0, 1])
    tn, fp, fn, tp = cm.ravel()
    
    # è¨ˆç®—å„é …æŒ‡æ¨™
    iou = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0
    dice = 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0
    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
    accuracy = (tp + tn) / (tp + tn + fp + fn)
    
    return {
        'IoU': iou,
        'Dice': dice,
        'Sensitivity': sensitivity,
        'Specificity': specificity,
        'Accuracy': accuracy
    }

# è¨˜æ†¶é«”æ¸…ç†å‡½æ•¸
def clear_memory():
    """æ¸…ç†GPUè¨˜æ†¶é«”"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    gc.collect()

# è¨“ç·´å‡½æ•¸
def train_model():
    # è¨­å®šéš¨æ©Ÿç¨®å­
    torch.manual_seed(42)
    random.seed(42)
    np.random.seed(42)
    
    # å‰µå»ºå„²å­˜ç›®éŒ„
    os.makedirs(Config.MODEL_SAVE_PATH, exist_ok=True)
    os.makedirs(Config.LOG_PATH, exist_ok=True)
    
    # è¼‰å…¥è³‡æ–™é›†è·¯å¾‘
    print("è¼‰å…¥è³‡æ–™é›†è·¯å¾‘...")
    image_paths, mask_paths = load_dataset_paths(Config.DATA_ROOT, Config.DATASETS)
    
    if len(image_paths) == 0:
        print("âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„å½±åƒ-é®ç½©é…å°ï¼")
        return None, None
    
    # åˆ†å‰²è³‡æ–™é›†
    print("\\nåˆ†å‰²è³‡æ–™é›†...")
    (train_images, train_masks), (val_images, val_masks), (test_images, test_masks) = split_dataset(
        image_paths, mask_paths, Config.TRAIN_RATIO, Config.VAL_RATIO, Config.TEST_RATIO
    )
    
    print(f"è¨“ç·´é›†: {len(train_images)} å¼µ")
    print(f"é©—è­‰é›†: {len(val_images)} å¼µ")
    print(f"æ¸¬è©¦é›†: {len(test_images)} å¼µ")
    
    # å‰µå»ºè³‡æ–™è¼‰å…¥å™¨
    train_dataset = VesselDataset(train_images, train_masks, target_size=Config.IMAGE_SIZE)
    val_dataset = VesselDataset(val_images, val_masks, target_size=Config.IMAGE_SIZE)
    
    # è¨­å®šè¼ƒå°‘çš„workeræ•¸é‡ä»¥ç¯€çœè¨˜æ†¶é«”
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True, 
                             num_workers=2, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False, 
                           num_workers=2, pin_memory=True)
    
    # åˆå§‹åŒ–æ¨¡å‹
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\\nä½¿ç”¨è¨­å‚™: {device}")
    
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name()}")
        print(f"GPUè¨˜æ†¶é«”: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    model = VesselCNN(num_classes=Config.NUM_CLASSES).to(device)
    
    # æå¤±å‡½æ•¸ (è™•ç†é¡åˆ¥ä¸å¹³è¡¡)
    # è¡€ç®¡åƒç´ é€šå¸¸è¼ƒå°‘ï¼Œçµ¦äºˆè¼ƒé«˜æ¬Šé‡
    class_weights = torch.FloatTensor([0.1, 0.9]).to(device)  # [èƒŒæ™¯, è¡€ç®¡]
    criterion = nn.CrossEntropyLoss(weight=class_weights)
    
    # å„ªåŒ–å™¨
    optimizer = optim.Adam(model.parameters(), lr=Config.LEARNING_RATE)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=10, factor=0.5)
    
    # è¨“ç·´è¨˜éŒ„
    train_losses = []
    val_metrics = []
    best_val_iou = 0.0
    
    print("\\né–‹å§‹è¨“ç·´...")
    print("=" * 60)
    
    for epoch in range(Config.EPOCHS):
        # æ¸…ç†è¨˜æ†¶é«”
        clear_memory()
        
        # è¨“ç·´éšæ®µ
        model.train()
        train_loss = 0.0
        
        for batch_idx, (images, masks) in enumerate(train_loader):
            images, masks = images.to(device), masks.to(device)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, masks)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            
            if batch_idx % 10 == 0:
                print(f'Epoch {epoch+1}/{Config.EPOCHS}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')
        
        avg_train_loss = train_loss / len(train_loader)
        train_losses.append(avg_train_loss)
        
        # é©—è­‰éšæ®µ
        model.eval()
        val_iou_total = 0.0
        val_dice_total = 0.0
        val_acc_total = 0.0
        
        with torch.no_grad():
            for images, masks in val_loader:
                images, masks = images.to(device), masks.to(device)
                outputs = model(images)
                
                # ç²å–é æ¸¬çµæœ
                _, predicted = torch.max(outputs, 1)
                
                # è¨ˆç®—æŒ‡æ¨™
                for i in range(images.size(0)):
                    metrics = calculate_metrics(predicted[i], masks[i])
                    val_iou_total += metrics['IoU']
                    val_dice_total += metrics['Dice']
                    val_acc_total += metrics['Accuracy']
        
        # è¨ˆç®—å¹³å‡æŒ‡æ¨™
        num_val_samples = len(val_loader.dataset)
        avg_val_iou = val_iou_total / num_val_samples
        avg_val_dice = val_dice_total / num_val_samples
        avg_val_acc = val_acc_total / num_val_samples
        
        val_metrics.append({
            'IoU': avg_val_iou,
            'Dice': avg_val_dice,
            'Accuracy': avg_val_acc
        })
        
        # å­¸ç¿’ç‡èª¿æ•´
        scheduler.step(avg_val_iou)
        
        print(f'\\nEpoch {epoch+1}/{Config.EPOCHS}:')
        print(f'  Train Loss: {avg_train_loss:.4f}')
        print(f'  Val IoU: {avg_val_iou:.4f}, Val Dice: {avg_val_dice:.4f}, Val Acc: {avg_val_acc:.4f}')
        print(f'  Learning Rate: {optimizer.param_groups[0]["lr"]:.6f}')
        
        if torch.cuda.is_available():
            memory_used = torch.cuda.memory_allocated() / 1024**3
            memory_cached = torch.cuda.memory_reserved() / 1024**3
            print(f'  GPUè¨˜æ†¶é«”: ä½¿ç”¨ {memory_used:.2f}GB, å¿«å– {memory_cached:.2f}GB')
        
        print('-' * 60)
        
        # å„²å­˜æœ€ä½³æ¨¡å‹ - ä¿®æ­£ pickle éŒ¯èª¤
        if avg_val_iou > best_val_iou:
            best_val_iou = avg_val_iou
            try:
                # ä½¿ç”¨ Config.to_dict() è€Œä¸æ˜¯ Config.__dict__
                torch.save({
                    'epoch': epoch + 1,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'best_val_iou': best_val_iou,
                    'config': Config.to_dict()  # ä¿®æ­£é€™è£¡ï¼
                }, os.path.join(Config.MODEL_SAVE_PATH, 'best_vessel_cnn.pth'))
                print(f'âœ… æ–°çš„æœ€ä½³æ¨¡å‹å·²å„²å­˜! IoU: {best_val_iou:.4f}')
            except Exception as e:
                print(f'âš ï¸ æ¨¡å‹å„²å­˜å¤±æ•—: {e}')
                # å˜—è©¦åªå„²å­˜æ¨¡å‹ç‹€æ…‹
                torch.save({
                    'epoch': epoch + 1,
                    'model_state_dict': model.state_dict(),
                    'best_val_iou': best_val_iou
                }, os.path.join(Config.MODEL_SAVE_PATH, 'best_vessel_cnn_simple.pth'))
                print('âœ… ç°¡åŒ–ç‰ˆæ¨¡å‹å·²å„²å­˜!')
    
    # å„²å­˜è¨“ç·´è¨˜éŒ„ - ä¹Ÿä¿®æ­£ pickle å•é¡Œ
    training_log = {
        'train_losses': train_losses,
        'val_metrics': val_metrics,
        'best_val_iou': best_val_iou,
        'config': Config.to_dict(),  # ä¿®æ­£é€™è£¡ï¼
        'timestamp': datetime.now().isoformat()
    }
    
    try:
        with open(os.path.join(Config.LOG_PATH, 'training_log.json'), 'w') as f:
            json.dump(training_log, f, indent=2)
        print("âœ… è¨“ç·´è¨˜éŒ„å·²å„²å­˜!")
    except Exception as e:
        print(f"âš ï¸ è¨“ç·´è¨˜éŒ„å„²å­˜å¤±æ•—: {e}")
    
    print(f"\\nğŸ‰ è¨“ç·´å®Œæˆ! æœ€ä½³é©—è­‰ IoU: {best_val_iou:.4f}")
    
    # åœ¨æ¸¬è©¦é›†ä¸Šè©•ä¼°
    print("\\nåœ¨æ¸¬è©¦é›†ä¸Šè©•ä¼°...")
    test_dataset = VesselDataset(test_images, test_masks, target_size=Config.IMAGE_SIZE)
    test_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, shuffle=False, 
                            num_workers=2, pin_memory=True)
    
    model.eval()
    test_metrics = []
    
    with torch.no_grad():
        for images, masks in test_loader:
            images, masks = images.to(device), masks.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            
            for i in range(images.size(0)):
                metrics = calculate_metrics(predicted[i], masks[i])
                test_metrics.append(metrics)
    
    # è¨ˆç®—å¹³å‡æ¸¬è©¦æŒ‡æ¨™
    avg_test_metrics = {}
    for key in test_metrics[0].keys():
        avg_test_metrics[key] = np.mean([m[key] for m in test_metrics])
    
    print("\\nğŸ“Š æ¸¬è©¦é›†çµæœ:")
    print("=" * 40)
    for key, value in avg_test_metrics.items():
        print(f"  {key}: {value:.4f}")
    print("=" * 40)
    
    return model, avg_test_metrics

if __name__ == "__main__":
    model, test_results = train_model()